Phase 1 model summary
This document is meant to be a summary of the models used on the Phase 1 data.
Provide the following details for EACH sub-challenge within “Summary-Phase1.txt”
------------------------------
Summary-Phase1-Sub-challenge-1
------------------------------
a) Provide a description of model settings and parameters, and details of model building including dataset(s) description(s) used for training, cross validation and testing (number of samples, number of features, etc.) 

The general idea is that we first perform feature selection, and then use h2o automl to pick the best performing model. This strategy is used in all 3 sub challenges. More Specifically, I used the idea and majority of the code from Xu et al 2019 (https://github.com/bioinformatics-xu/AutoBorutaRF/blob/master/AutoencoderBoruta.R) for feature selection. The first step is to use an autoencoder for unsupervised feature selection, top 10% of the features are picked. Then the data is randomly divided into training and test set with 80/20 split. The second step is to use Boruta, which uses random forest for selecting features that are corrected with the outcome. Since we have unbalanced classes, the majority class was divided into k groups, where k is roughly the class inbalance. Features selected from each Boruta run were concatenated.  Upon investigating the correlation of the phenotypes with the outcome, I decided to keep only the SEX and CANCER_TYPE. I assigned both "UNCLASSIFIED" and "UNKNOWN" as missing data, and did one hot encoding. Finally, I used h2o automl to train the model with selected features as well as SEX and one hot encoded CANCER_TYPE. Default parameters were used for h2o automl except that balance_classes is set to TRUE,which tells automl to oversample the minority classes to balance the class distribution. The best performing model is evaluated against the test set. The performance estimates are based on evaluation on the test set.   

b) Short listed features selected by the model
AKR1C4
DPY19L1P1
GRB14
LINC00619
MIR548XHG
NUDT13
RPS6KL1
SLC38A3
SPARCL1
SYCP2
ULBP2
ZHX1.C8orf76
ADGRG6
ALOX12.AS1
BBS2
CALCB
CCDC142
CTH
DHRS1
DLX6.AS1
GRTP1
HAUS2
MATN3
MPG
MTOR
MYOC
NIT1
PLAA
TRPT1
ATP6V0E2.AS1
CD47
IDH3B
LINC01858
LRRC37B
NPHP3
PLEKHA3
SNED1
THYN1
ZNF785
ANKS1A
APMAP
CDKN2B
CHODL
CYP2J2
DHRS7
ETFDH
KNSTRN
LINC01116
LPCAT1
PHF20
SHISA9
TAL1
ABCC4
GGNBP2
GRIK1
LGR4
PDPR
DUSP1
EIF4ENIF1
FOXA1
HMGB4
HOXC9
LINC02114
LOC644135
SEX
CANCER_TYPE

c) Link to complete code in a public GitHub repository 

https://github.com/shukwong/precisionFDA_BrainCancer

src/01_preprocess_s1.Rmd
src/02_autoencoderBoruta_s1.Rmd
src/03_h2o_automl_s1.Rmd

d) Confusion matrix indicating number of predictions, true positives, false positives, true negatives, and false negatives 

          Reference
Prediction  0  1
         0  5  4
         1  5 61

e) Overall accuracy 

0.88

f) Specificity

0.5000  

g) Sensitivity 

0.9385  

h) Area under the curve (AUC)

0.7877

------------------------------
Summary-Phase1-Sub-challenge-2
------------------------------
a) Provide a description of model settings and parameters, and details of model building including dataset(s) description(s) used for training, cross validation and testing (number of samples, number of features, etc.) 

The methods were the same as sub challenge 1 except that I excluded GBM as one of the algorithms to be tested for automl, because h2o GBM seems to have some problems with a small number of samples. 


b) Short listed features selected by the model

5q33.2
9p24.3
9q33.2
14q22.3
20p11.22
22q13.33
2q21.3
3q26.32
SEX
CANCER_TYPE


c) Link to complete code in a public GitHub repository 

https://github.com/shukwong/precisionFDA_BrainCancer

src/04_preprocess_s2.Rmd
src/05_autoencoderBoruta_s2.Rmd
src/06_h2o_automl_s2.Rmd


d) Confusion matrix indicating number of predictions, true positives, false positives, true negatives, and false negatives 

          Reference
Prediction  0  1
         0  3  8
         1  5 18

e) Overall accuracy 

0.6176

f) Specificity

0.3750  

g) Sensitivity 

0.6923    

h) Area under the curve (AUC)

0.5433

------------------------------
Summary-Phase1-Sub-challenge-3
------------------------------
a) Provide a description of model settings and parameters, and details of model building including dataset(s) description(s) used for training, cross validation and testing (number of samples, number of features, etc.) 

The features selected in sub challenge 1 and 2 were used for h2o automl. In 07_h2o_automl_s3.Rmd I used the same methods described above to train model using the features selected. However, I believe this is not the best way because the sample size here is a lot smaller. Therefore I created an ensembled model from the top models from sub challenges 1 and 2, weighted by their accuracy. This is implemented in 08_s3_model_using_s1_s2.Rmd

Note that the performance measure here is tricky. As all but one samples were included in sub challenges 1 and 2. To have a better estimate of performance we need independent data set. I first attemped using only those patients in both of the test sets, but there were too few of them. I decided to take those test data that was at least in one test sets, this results in 51 samples, of which 38 are positive samples. Since this is not a true independent set, I believe the performance metrics may be a bit inflated.

b) Short listed features selected by the model

The features are the union of those selected in sub challenges 1 and 2. To avoid clutter, I am not going to include them here. Please see above. 

c) Link to complete code in a public GitHub repository 

https://github.com/shukwong/precisionFDA_BrainCancer

src/08_s3_model_using_s1_s2.Rmd


d) Confusion matrix indicating number of predictions, true positives, false positives, true negatives, and false negatives 

##           Reference
## Prediction  0  1
##          0 10  2
##          1  3 36

e) Overall accuracy 

0.902

f) Specificity

0.7692

g) Sensitivity 

0.9474

h) Area under the curve (AUC)

0.8806



Reference

Xu X, Gu H, Wang Y, Wang J, Qin P. Autoencoder Based Feature Selection Method for Classification of Anticancer Drug Response. Front Genet. 2019;10: 233.